{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOANLlfW9b62lWVv6iYHMU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thrillcrazyer/Deep-Learning-with-TensorFlow-2-and-Keras-in-colab-/blob/master/chap04/Deep_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 심층 신경망으로 CIFAR-10 성능 향상\n",
        "\n"
      ],
      "metadata": {
        "id": "fZKuxnTgdABm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxl_y26tc50z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets,layers,models,regularizers,optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "EPOCHS=50\n",
        "NUM_CLASSES= 10\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  (x_train,y_train),(x_test,y_test) = datasets.cifar10.load_data()\n",
        "  x_train= x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "\n",
        "  #정규화\n",
        "  mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "  std= np.std(x_train,axis=(0,1,2,3))\n",
        "  x_train = (x_train-mean)/(std+1e-7)\n",
        "  x_test= (x_test-mean)/(std+1e-7)\n",
        "\n",
        "  y_train= tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
        "  y_test= tf.keras.utils.to_categorical(y_test,NUM_CLASSES)\n",
        "  \n",
        "  return x_train,y_train,x_test,y_test\n"
      ],
      "metadata": {
        "id": "xyCX9ze9kpSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model= models.Sequential()\n",
        "  \n",
        "  # 첫번째 블록\n",
        "  model.add(layers.Conv2D(32,(3,3),padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "\n",
        "   # 두번째 블록\n",
        "  model.add(layers.Conv2D(64,(3,3),padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.3)) \n",
        "\n",
        "   # 세번째 블록\n",
        "  model.add(layers.Conv2D(128,(3,3),padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128,(3,3),padding='same',activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  #밀집 출력 계층\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(NUM_CLASSES,activation='softmax'))\n",
        "\n",
        "  return model\n",
        "  model.summary()"
      ],
      "metadata": {
        "id": "jSC8_rdHkrtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train,x_test,y_test) =load_data()\n",
        "model = build_model()\n",
        "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['accuracy'])\n",
        "\n",
        "#훈련\n",
        "batch_size=64\n",
        "model.fit(x_train,y_train,batch_size=batch_size,epochs=EPOCHS, validation_data=(x_test,y_test))\n",
        "score = model.evaluate(x_test,y_test,batch_size=batch_size)\n",
        "\n",
        "print(\"\\nTest score: \",score[0])\n",
        "print(\"Test accuracy\",score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RC7S3UoS1B",
        "outputId": "e82db5a3-a08d-42d8-d5ee-12207831bf1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 21s 12ms/step - loss: 1.7192 - accuracy: 0.4835 - val_loss: 1.3259 - val_accuracy: 0.5808\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.0726 - accuracy: 0.6536 - val_loss: 1.0446 - val_accuracy: 0.6902\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8572 - accuracy: 0.7134 - val_loss: 0.8561 - val_accuracy: 0.7152\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7296 - accuracy: 0.7534 - val_loss: 0.7284 - val_accuracy: 0.7531\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.6552 - accuracy: 0.7771 - val_loss: 0.6955 - val_accuracy: 0.7685\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5951 - accuracy: 0.7960 - val_loss: 0.6791 - val_accuracy: 0.7637\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5447 - accuracy: 0.8123 - val_loss: 0.5711 - val_accuracy: 0.8081\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5027 - accuracy: 0.8270 - val_loss: 0.5337 - val_accuracy: 0.8175\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4698 - accuracy: 0.8365 - val_loss: 0.5567 - val_accuracy: 0.8142\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4387 - accuracy: 0.8466 - val_loss: 0.5141 - val_accuracy: 0.8293\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4225 - accuracy: 0.8527 - val_loss: 0.5292 - val_accuracy: 0.8257\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4001 - accuracy: 0.8600 - val_loss: 0.5061 - val_accuracy: 0.8319\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3760 - accuracy: 0.8682 - val_loss: 0.6235 - val_accuracy: 0.8046\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3638 - accuracy: 0.8719 - val_loss: 0.5332 - val_accuracy: 0.8270\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3480 - accuracy: 0.8777 - val_loss: 0.5193 - val_accuracy: 0.8327\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3327 - accuracy: 0.8819 - val_loss: 0.5081 - val_accuracy: 0.8351\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3229 - accuracy: 0.8865 - val_loss: 0.4860 - val_accuracy: 0.8403\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3098 - accuracy: 0.8890 - val_loss: 0.4962 - val_accuracy: 0.8407\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2964 - accuracy: 0.8951 - val_loss: 0.4749 - val_accuracy: 0.8489\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2895 - accuracy: 0.8974 - val_loss: 0.4922 - val_accuracy: 0.8393\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2771 - accuracy: 0.9013 - val_loss: 0.4990 - val_accuracy: 0.8454\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2721 - accuracy: 0.9028 - val_loss: 0.5031 - val_accuracy: 0.8430\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2592 - accuracy: 0.9087 - val_loss: 0.5130 - val_accuracy: 0.8406\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2564 - accuracy: 0.9079 - val_loss: 0.4943 - val_accuracy: 0.8465\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2467 - accuracy: 0.9113 - val_loss: 0.4973 - val_accuracy: 0.8471\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.2387 - accuracy: 0.9156 - val_loss: 0.4873 - val_accuracy: 0.8531\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2377 - accuracy: 0.9156 - val_loss: 0.4997 - val_accuracy: 0.8490\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2264 - accuracy: 0.9198 - val_loss: 0.4986 - val_accuracy: 0.8469\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2217 - accuracy: 0.9189 - val_loss: 0.5117 - val_accuracy: 0.8457\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2209 - accuracy: 0.9208 - val_loss: 0.4791 - val_accuracy: 0.8565\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2203 - accuracy: 0.9221 - val_loss: 0.5014 - val_accuracy: 0.8520\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2120 - accuracy: 0.9242 - val_loss: 0.5066 - val_accuracy: 0.8505\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2105 - accuracy: 0.9243 - val_loss: 0.4980 - val_accuracy: 0.8500\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2039 - accuracy: 0.9267 - val_loss: 0.4896 - val_accuracy: 0.8560\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1971 - accuracy: 0.9313 - val_loss: 0.4819 - val_accuracy: 0.8546\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1971 - accuracy: 0.9294 - val_loss: 0.5193 - val_accuracy: 0.8530\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1879 - accuracy: 0.9317 - val_loss: 0.4943 - val_accuracy: 0.8588\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1867 - accuracy: 0.9349 - val_loss: 0.5177 - val_accuracy: 0.8532\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1851 - accuracy: 0.9334 - val_loss: 0.5205 - val_accuracy: 0.8541\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1869 - accuracy: 0.9332 - val_loss: 0.4871 - val_accuracy: 0.8570\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1807 - accuracy: 0.9343 - val_loss: 0.5249 - val_accuracy: 0.8539\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1769 - accuracy: 0.9363 - val_loss: 0.4968 - val_accuracy: 0.8593\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.1752 - accuracy: 0.9366 - val_loss: 0.4863 - val_accuracy: 0.8646\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1695 - accuracy: 0.9393 - val_loss: 0.5079 - val_accuracy: 0.8594\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1698 - accuracy: 0.9396 - val_loss: 0.5081 - val_accuracy: 0.8597\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1683 - accuracy: 0.9402 - val_loss: 0.5045 - val_accuracy: 0.8615\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1678 - accuracy: 0.9398 - val_loss: 0.5119 - val_accuracy: 0.8583\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1627 - accuracy: 0.9425 - val_loss: 0.5104 - val_accuracy: 0.8545\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1604 - accuracy: 0.9426 - val_loss: 0.5070 - val_accuracy: 0.8589\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.1580 - accuracy: 0.9439 - val_loss: 0.5076 - val_accuracy: 0.8571\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5076 - accuracy: 0.8571\n",
            "\n",
            "Test score:  0.5076322555541992\n",
            "Test accuracy 0.8571000099182129\n"
          ]
        }
      ]
    }
  ]
}