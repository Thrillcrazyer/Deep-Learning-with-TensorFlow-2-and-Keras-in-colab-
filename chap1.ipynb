{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chap1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPxxJHFe40k8rcBpnUhgjH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thrillcrazyer/Deep-Learning-with-TensorFlow-2-and-Keras-in-colab-/blob/master/chap1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1 code\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lGt7bCpUe8OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "NB_CLASSES= 10\n",
        "RESHAPED= 784\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(NB_CLASSES,input_shape=(RESHAPED,), kernel_initializer='zeros', name='dense_layer',activation='softmax'))"
      ],
      "metadata": {
        "id": "yaxKs6asfFuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서플로 2.0 기본훈련 (mnist)"
      ],
      "metadata": {
        "id": "I53mHyuxIdUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "#신경망과 훈련 매개변수\n",
        "EPOCHS = 200 #훈련의 지속수\n",
        "BATCH_SIZE=128\n",
        "VERBOSE =1\n",
        "NB_CLASSES = 10 # 출력개수 =숫자의 개수\n",
        "N_HIDDEN= 128\n",
        "VALIDATION_SPLIT = 0.2 #검증을 위해 남겨둔 훈련 데이터\n",
        "\n",
        "#MNIST 데이터셋 로드\n",
        "#검증\n",
        "#훈련과 테스트 데이터를 각각 60000개와 10000개로 나눈것을 알 수 있다.\n",
        "#레이블에 대한 원핫 인코딩은 자동으로 적용된다.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train),(X_test,Y_test)= mnist.load_data()\n",
        "\n",
        "#X_train은 60000개 행으로 28X28 값을 가진다. 이를 60000X784 형태로 변환\n",
        "RESHAPED=784\n",
        "\n",
        "X_train =X_train.reshape(60000,RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "#입력을 [0,1]로 정규화\n",
        "X_train = X_train/255\n",
        "X_test =X_test/255\n",
        "print(X_train.shape[0],'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "#레이블을 원핫 인코딩\n",
        "Y_train= tf.keras.utils.to_categorical(Y_train,NB_CLASSES)\n",
        "Y_test= tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "#모델 구축\n",
        "model= tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(NB_CLASSES,input_shape=(RESHAPED,), name='dense_layer', activation = 'softmax'))\n",
        "\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(optimizer= 'SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#모델 훈련\n",
        "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#모델 평가\n",
        "test_loss, test_acc=model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: ', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "sWWj46cqiJ1e",
        "outputId": "1e1ee0b7-755e-4f65-f184-56c3b2bf51aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/200\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 1.3867 - accuracy: 0.6629 - val_loss: 0.8957 - val_accuracy: 0.8273\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7918 - accuracy: 0.8288 - val_loss: 0.6568 - val_accuracy: 0.8576\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6412 - accuracy: 0.8509 - val_loss: 0.5609 - val_accuracy: 0.8704\n",
            "Epoch 4/200\n",
            " 88/375 [======>.......................] - ETA: 0s - loss: 0.5979 - accuracy: 0.8547"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-54f4210505fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#모델 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서플로 2.0의 단순 신경망을 은닉층으로 개선"
      ],
      "metadata": {
        "id": "9ZnX64OUIlsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "#신경망과 훈련 매개변수\n",
        "EPOCHS = 50 #훈련의 지속수\n",
        "BATCH_SIZE=128\n",
        "VERBOSE =1\n",
        "NB_CLASSES = 10 # 출력개수 =숫자의 개수\n",
        "N_HIDDEN= 128\n",
        "VALIDATION_SPLIT = 0.2 #검증을 위해 남겨둔 훈련 데이터\n",
        "\n",
        "#MNIST 데이터셋 로드\n",
        "#검증\n",
        "#훈련과 테스트 데이터를 각각 60000개와 10000개로 나눈것을 알 수 있다.\n",
        "#레이블에 대한 원핫 인코딩은 자동으로 적용된다.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train),(X_test,Y_test)= mnist.load_data()\n",
        "\n",
        "#X_train은 60000개 행으로 28X28 값을 가진다. 이를 60000X784 형태로 변환\n",
        "RESHAPED=784\n",
        "\n",
        "X_train =X_train.reshape(60000,RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "#입력을 [0,1]로 정규화\n",
        "X_train = X_train/255\n",
        "X_test =X_test/255\n",
        "print(X_train.shape[0],'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "#레이블을 원핫 인코딩\n",
        "Y_train= tf.keras.utils.to_categorical(Y_train,NB_CLASSES)\n",
        "Y_test= tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "#모델 구축\n",
        "model= tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(N_HIDDEN,input_shape=(RESHAPED,),name='dense_layer',activation='relu'))\n",
        "model.add(keras.layers.Dense(N_HIDDEN,input_shape=(RESHAPED,),name='dense_layer_2',activation='relu'))\n",
        "model.add(keras.layers.Dense(NB_CLASSES,input_shape=(RESHAPED,), name='dense_layer_3', activation = 'softmax'))\n",
        "\n",
        "#모델요약\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(optimizer= 'SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#모델 훈련\n",
        "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#모델 평가\n",
        "test_loss, test_acc=model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: ', test_acc)\n"
      ],
      "metadata": {
        "id": "MjLxPLX2Irs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서플로에서 드롭아웃으로 단순망 개선"
      ],
      "metadata": {
        "id": "f5RDbysLML3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "#신경망과 훈련 매개변수\n",
        "EPOCHS = 50 #훈련의 지속수\n",
        "BATCH_SIZE=128\n",
        "VERBOSE =1\n",
        "NB_CLASSES = 10 # 출력개수 =숫자의 개수\n",
        "N_HIDDEN= 128\n",
        "VALIDATION_SPLIT = 0.2 #검증을 위해 남겨둔 훈련 데이터\n",
        "DROPOUT=0.3\n",
        "\n",
        "#MNIST 데이터셋 로드\n",
        "#검증\n",
        "#훈련과 테스트 데이터를 각각 60000개와 10000개로 나눈것을 알 수 있다.\n",
        "#레이블에 대한 원핫 인코딩은 자동으로 적용된다.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train),(X_test,Y_test)= mnist.load_data()\n",
        "\n",
        "#X_train은 60000개 행으로 28X28 값을 가진다. 이를 60000X784 형태로 변환\n",
        "RESHAPED=784\n",
        "\n",
        "X_train =X_train.reshape(60000,RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "#입력을 [0,1]로 정규화\n",
        "X_train = X_train/255\n",
        "X_test =X_test/255\n",
        "print(X_train.shape[0],'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "#레이블을 원핫 인코딩\n",
        "Y_train= tf.keras.utils.to_categorical(Y_train,NB_CLASSES)\n",
        "Y_test= tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "#모델 구축\n",
        "model= tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(N_HIDDEN,input_shape=(RESHAPED,),name='dense_layer',activation='relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(N_HIDDEN,input_shape=(RESHAPED,),name='dense_layer_2',activation='relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(NB_CLASSES,input_shape=(RESHAPED,), name='dense_layer_3', activation = 'softmax'))\n",
        "\n",
        "#모델요약\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(optimizer= 'SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#모델 훈련\n",
        "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#모델 평가\n",
        "test_loss, test_acc=model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: ', test_acc)"
      ],
      "metadata": {
        "id": "tfiqd6DFMQEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 감정분석(Colab 테스트 코드)"
      ],
      "metadata": {
        "id": "X5axPknGRrJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets,layers,models,preprocessing\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "max_len=200\n",
        "n_words=10000\n",
        "dim_embedding=256\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE= 500\n",
        "\n",
        "def load_data():\n",
        "  # 데이터 로드\n",
        "  (X_train,y_train),(X_test,y_test) = datasets.imdb.load_data(num_words=n_words)\n",
        "  # 문장을 max_len이 되도록 채워 넣는다.\n",
        "  X_train = preprocessing.sequence.pad_sequences(X_train,maxlen=max_len) \n",
        "  X_test = preprocessing.sequence.pad_sequences(X_test,maxlen=max_len) \n",
        "  return (X_train,y_train), (X_test,y_test)\n",
        "\n",
        "def build_model():\n",
        "  model= models.Sequential()\n",
        "  # 입력: -eEmbedding Layer\n",
        "  # 모델은 크기의 정수 행렬을 입력으로 취한다.(batch, input_length).\n",
        "  # 모델의 출력은 차원이다.(input_length, dim_embedding)\n",
        "  # 입력 중 가장 큰 정수는 n_words보다 작거나 같다(어휘 크기).\n",
        "  model.add(layers.Embedding(n_words,dim_embedding, input_length=max_len))\n",
        "\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  #각 n_words 특징에서 특징 벡터의 최댓값을 취한다.\n",
        "\n",
        "  model.add(layers.GlobalMaxPooling1D())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(1,activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "(X_train,y_train), (X_test,y_test) =load_data()\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "#모델 컴파일\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "#모델 평가\n",
        "score= model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data = (X_test, y_test))\n",
        "\n",
        "score=model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
        "print(\"\\nTest score\", score[0])\n",
        "print(\"Test accuracy\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0llgrrDRzZH",
        "outputId": "03b12aa8-881a-4ee9-c4ca-c3a5490090e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 256)          2560000   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200, 256)          0         \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,593,025\n",
            "Trainable params: 2,593,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50/50 [==============================] - 27s 520ms/step - loss: 0.6688 - accuracy: 0.6293 - val_loss: 0.6197 - val_accuracy: 0.8276\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 25s 497ms/step - loss: 0.4417 - accuracy: 0.8422 - val_loss: 0.3527 - val_accuracy: 0.8616\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 25s 493ms/step - loss: 0.2684 - accuracy: 0.8916 - val_loss: 0.3000 - val_accuracy: 0.8773\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 25s 502ms/step - loss: 0.2081 - accuracy: 0.9204 - val_loss: 0.2935 - val_accuracy: 0.8756\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 25s 496ms/step - loss: 0.1620 - accuracy: 0.9411 - val_loss: 0.2910 - val_accuracy: 0.8757\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 25s 504ms/step - loss: 0.1249 - accuracy: 0.9583 - val_loss: 0.2965 - val_accuracy: 0.8732\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 26s 519ms/step - loss: 0.0978 - accuracy: 0.9689 - val_loss: 0.3081 - val_accuracy: 0.8707\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 25s 496ms/step - loss: 0.0716 - accuracy: 0.9794 - val_loss: 0.3245 - val_accuracy: 0.8659\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 25s 500ms/step - loss: 0.0537 - accuracy: 0.9853 - val_loss: 0.3402 - val_accuracy: 0.8646\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 25s 499ms/step - loss: 0.0398 - accuracy: 0.9900 - val_loss: 0.3579 - val_accuracy: 0.8610\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 25s 499ms/step - loss: 0.0287 - accuracy: 0.9948 - val_loss: 0.3793 - val_accuracy: 0.8580\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 25s 505ms/step - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.3990 - val_accuracy: 0.8558\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 24s 490ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.4216 - val_accuracy: 0.8532\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 25s 500ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.4287 - val_accuracy: 0.8548\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 25s 494ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.4479 - val_accuracy: 0.8519\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 25s 495ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.4646 - val_accuracy: 0.8512\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 25s 493ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.4774 - val_accuracy: 0.8505\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 24s 490ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.4923 - val_accuracy: 0.8486\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 26s 511ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.4986 - val_accuracy: 0.8493\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 25s 494ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.5188 - val_accuracy: 0.8475\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.5188 - accuracy: 0.8475\n",
            "\n",
            "Test score 0.5187954902648926\n",
            "Test accuracy 0.8475199937820435\n"
          ]
        }
      ]
    }
  ]
}